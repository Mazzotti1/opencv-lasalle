{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd35784f",
   "metadata": {},
   "source": [
    " Pipeline de Pré-Processamento de Imagens – Letras A, B e C\n",
    "\n",
    "Neste notebook, realizamos um pipeline de pré-processamento em imagens da Língua de Sinais Americana (ASL), especificamente para as letras A, B e C.\n",
    " Etapas Realizadas:\n",
    "\n",
    "    Leitura das Imagens\n",
    "    As imagens são carregadas a partir das subpastas do dataset, separadas por letra.\n",
    "\n",
    "     Redimensionamento\n",
    "     Todas as imagens serão redimensionadas para um tamanho fixo de 200x200 px para ter uma consistência na análise posterior.\n",
    "\n",
    "     Conversão para Escala de Cinza\n",
    "    As imagens coloridas serão convertidas para **escala de cinza** para simplificar a análise, removendo as informações de cor.\n",
    "\n",
    "     Ajuste de Brilho e Contraste\n",
    "    Aplicação de ajustes personalizados para melhorar a visibilidade das regiões de interesse nas imagens.\n",
    "\n",
    "     Limiarização (Thresholding)\n",
    "    Aplicação do método de Otsu para segmentar objetos em primeiro plano, separando-os do fundo.\n",
    "\n",
    "     Segmentação por Cor em HSV\n",
    "    Detecção de regiões da pele com base em um intervalo HSV, destacando as mãos nas imagens.\n",
    "\n",
    "     Detecção de Contornos e Caixas Delimitadoras\n",
    "    Identificação dos contornos dos objetos e desenho de bounding boxes com a respectiva área anotada.\n",
    "\n",
    "     Visualização e Salvamento de Resultados\n",
    "    Para cada imagem, é gerado um grid comparativo com todas as etapas aplicadas e salvo para análise posterior.\n",
    "\n",
    "Passos:\n",
    "\n",
    "Leitura das Imagens: As imagens de cada letra (A, B, C) foram lidas a partir da pasta correspondente.\n",
    "\n",
    "Redimensionamento: Cada imagem foi redimensionada para 200x200 px usando o OpenCV.\n",
    "\n",
    "Conversão para Escala de Cinza: As imagens foram convertidas para escala de cinza para reduzir a complexidade e facilitar o processamento posterior.\n",
    "\n",
    "Ajuste de Brilho/Contraste: Um leve ajuste de brilho (+10) e contraste (+20) foi aplicado para realçar as regiões relevantes da imagem.\n",
    "\n",
    "Thresholding (Otsu): Aplicada a técnica de Otsu para destacar as regiões da mão e separar o fundo.\n",
    "\n",
    "Segmentação de Cor (HSV): Realizada para isolar áreas com tonalidades de pele humana.\n",
    "\n",
    "Detecção de Contornos: Utilizou-se cv2.findContours para identificar objetos e desenhar caixas delimitadoras ao redor de contornos relevantes.\n",
    "\n",
    "Visualização Final: Todas as etapas acima são exibidas em subplots e salvas automaticamente em disco para referência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62718da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Configuração dos paths\n",
    "base_path = Path(\"dataset\")\n",
    "letters = ['A', 'B', 'C']\n",
    "output_path = Path(\"images_result\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "(output_path / 'processed').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Função para criar e salvar o grid combinado\n",
    "def save_combined_plot(processed_imgs, letter, output_dir, img_name):\n",
    "    \"\"\"Cria e salva uma imagem combinada com todos os subplots\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    subplots = [\n",
    "        {'key': 'original', 'title': 'Original Image', 'cmap': None},\n",
    "        {'key': 'gray', 'title': 'Gray Scale', 'cmap': 'gray'},\n",
    "        {'key': 'adjusted', 'title': 'Brightness/Contrast Adjusted', 'cmap': None},\n",
    "        {'key': 'threshold', 'title': 'Threshold (Otsu)', 'cmap': 'gray'},\n",
    "        {'key': 'color_seg', 'title': 'Color Segmentation', 'cmap': None},\n",
    "        {'key': 'with_boxes', 'title': 'Contours & Bounding Boxes', 'cmap': None}\n",
    "    ]\n",
    "    \n",
    "    for i, plot in enumerate(subplots, start=1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        img = processed_imgs[plot['key']]\n",
    "        if plot['cmap'] is None and len(img.shape) == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img, cmap=plot['cmap'])\n",
    "        plt.title(plot['title'])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Processamento para Letra {letter} - {img_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    output_file = output_dir / f'{letter}_{img_name}_combined.png'\n",
    "    plt.savefig(str(output_file), bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "# Funções de processamento (mantidas as mesmas)\n",
    "def adjust_brightness_contrast(img, brightness=0, contrast=0):\n",
    "    brightness = brightness * 2.55\n",
    "    contrast = contrast * 2.55\n",
    "    \n",
    "    if brightness != 0:\n",
    "        if brightness > 0:\n",
    "            shadow = brightness\n",
    "            highlight = 255\n",
    "        else:\n",
    "            shadow = 0\n",
    "            highlight = 255 + brightness\n",
    "        alpha = (highlight - shadow)/255\n",
    "        gamma = shadow\n",
    "        img = cv2.addWeighted(img, alpha, img, 0, gamma)\n",
    "    \n",
    "    if contrast != 0:\n",
    "        f = 131*(contrast + 127)/(127*(131-contrast))\n",
    "        alpha_c = f\n",
    "        gamma_c = 127*(1-f)\n",
    "        img = cv2.addWeighted(img, alpha_c, img, 0, gamma_c)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def apply_thresholding(img, method='otsu'):\n",
    "    if method == 'otsu':\n",
    "        _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    elif method == 'adaptive':\n",
    "        thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                      cv2.THRESH_BINARY, 11, 2)\n",
    "    else:\n",
    "        _, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    return thresh\n",
    "\n",
    "def color_segmentation_hsv(img, lower_hsv, upper_hsv):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_hsv, upper_hsv)\n",
    "    result = cv2.bitwise_and(img, img, mask=mask)\n",
    "    return result, mask\n",
    "\n",
    "def find_contours_and_draw_boxes(img, original_img=None, min_area=500):\n",
    "    img_with_boxes = original_img.copy() if original_img is not None else img.copy()\n",
    "    if len(img_with_boxes.shape) == 2:\n",
    "        img_with_boxes = cv2.cvtColor(img_with_boxes, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > min_area:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(img_with_boxes, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(img_with_boxes, f'Area: {area}', (x, y-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    return img_with_boxes\n",
    "\n",
    "def resize(path_img):\n",
    "    img = cv2.imread(str(path_img))\n",
    "    img_resize = cv2.resize(img, (200, 200))\n",
    "    return img_resize\n",
    "\n",
    "def to_gray_scale(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img_gray\n",
    "\n",
    "def process_img(path_img, letter):\n",
    "    img_resized = resize(path_img)\n",
    "    img_adjusted = adjust_brightness_contrast(img_resized.copy(), brightness=10, contrast=20)\n",
    "    img_gray = to_gray_scale(img_adjusted.copy())\n",
    "    img_thresh = apply_thresholding(img_gray.copy(), method='otsu')\n",
    "    \n",
    "    lower_skin = np.array([0, 48, 80], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    img_color_seg, mask_color = color_segmentation_hsv(img_resized.copy(), lower_skin, upper_skin)\n",
    "    \n",
    "    img_with_boxes = find_contours_and_draw_boxes(img_thresh.copy(), img_resized.copy())\n",
    "    cv2.putText(img_with_boxes, f'Letter: {letter}', (10, 30), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    return {\n",
    "        'original': img_resized,\n",
    "        'gray': img_gray,\n",
    "        'adjusted': img_adjusted,\n",
    "        'threshold': img_thresh,\n",
    "        'color_seg': img_color_seg,\n",
    "        'color_mask': mask_color,\n",
    "        'with_boxes': img_with_boxes\n",
    "    }\n",
    "\n",
    "# Verificação inicial do dataset\n",
    "print(\"=== Verificação do Dataset ===\")\n",
    "total_imgs = 0\n",
    "for letter in letters:\n",
    "    dir = base_path / letter\n",
    "    count = len(os.listdir(dir))\n",
    "    print(f\"Letra {letter}: {count} imagens\")\n",
    "    total_imgs += count\n",
    "print(f\"\\nTotal de imagens a processar: {total_imgs}\\n\")\n",
    "\n",
    "# Processamento principal\n",
    "print(\"=== Iniciando Processamento ===\")\n",
    "example_shown = {letter: False for letter in letters}  # Controla exemplos mostrados\n",
    "\n",
    "for letter in letters:\n",
    "    dir = base_path / letter\n",
    "    \n",
    "    for img_file in os.listdir(dir):\n",
    "        img_path = dir / img_file\n",
    "        img_name = os.path.splitext(img_file)[0]\n",
    "        \n",
    "        print(f\"Processando: {img_path}\")\n",
    "        processed_imgs = process_img(img_path, letter)\n",
    "        \n",
    "        # Salva o grid combinado\n",
    "        save_combined_plot(processed_imgs, letter, output_path / 'processed', img_name)\n",
    "        \n",
    "        # Mostra apenas o primeiro exemplo de cada letra\n",
    "        if not example_shown[letter]:\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Recria os subplots para exibição\n",
    "            subplots = [\n",
    "                {'key': 'original', 'title': 'Original Image', 'cmap': None},\n",
    "                {'key': 'gray', 'title': 'Gray Scale', 'cmap': 'gray'},\n",
    "                {'key': 'adjusted', 'title': 'Brightness/Contrast Adjusted', 'cmap': None},\n",
    "                {'key': 'threshold', 'title': 'Threshold (Otsu)', 'cmap': 'gray'},\n",
    "                {'key': 'color_seg', 'title': 'Color Segmentation', 'cmap': None},\n",
    "                {'key': 'with_boxes', 'title': 'Contours & Bounding Boxes', 'cmap': None}\n",
    "            ]\n",
    "            \n",
    "            for i, plot in enumerate(subplots, start=1):\n",
    "                plt.subplot(2, 3, i)\n",
    "                img = processed_imgs[plot['key']]\n",
    "                if plot['cmap'] is None and len(img.shape) == 3:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                plt.imshow(img, cmap=plot['cmap'])\n",
    "                plt.title(plot['title'])\n",
    "                plt.axis('off')\n",
    "            \n",
    "            plt.suptitle(f'Exemplo para Letra {letter}', fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            example_shown[letter] = True\n",
    "\n",
    "print(\"\\nProcessamento concluído! Todas as imagens foram salvas em:\", output_path / 'processed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
